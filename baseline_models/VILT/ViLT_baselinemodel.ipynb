{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install Required Libraries"
      ],
      "metadata": {
        "id": "WryiJQlc3auQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmU0xWnzgg_l"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers accelerate git+https://github.com/facebookresearch/detr.git -q\n",
        "!pip install torch torchvision -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access image folder and CSV file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ss81oAeFzDVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Python Libraries"
      ],
      "metadata": {
        "id": "4tx2QRKG3iF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import ViltProcessor, ViltForQuestionAnswering\n",
        "from PIL import Image\n",
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "GpyO257AiH1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load VILT Processor and Model"
      ],
      "metadata": {
        "id": "BEETm9Ai3pDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load processor and model for VILT QnA\n",
        "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
        "model = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\").to(device)\n"
      ],
      "metadata": {
        "id": "7td2n0WLiJ5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load CSV and Format Questions"
      ],
      "metadata": {
        "id": "QmiCAWOz3_wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your CSV from Google Drive\n",
        "csv_file_path = '/content/drive/MyDrive/VR_proj2/proper_result_2_final.csv'  # Modify path accordingly\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Add constraint to each question for one-word answer\n",
        "df['question'] = df['question'].apply(lambda q: f\"Answer in one word: {q.strip()}\")\n",
        "\n",
        "# Save back or to a new CSV\n",
        "df.to_csv(\"/content/drive/MyDrive/VR_proj2/test_1_oneword.csv\", index=False)\n",
        "print(\"Updated CSV saved as test_1_oneword.csv with 'Answer in one word' prompt.\")\n"
      ],
      "metadata": {
        "id": "q5OTEDgLiNom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Run VILT Model on Each Image-Question Pair"
      ],
      "metadata": {
        "id": "goZToJ2B4CAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set row range for batch processing\n",
        "start_idx = 50000\n",
        "end_idx = 60000  # exclusive, so rows 0 to 19\n",
        "subset_df = df.iloc[start_idx:end_idx]\n",
        "results = []\n",
        "\n",
        "# Process each row\n",
        "for idx, row in tqdm(subset_df.iterrows(), total=len(subset_df), desc=\"Running VILT on selected rows\"):\n",
        "    image_path = os.path.join(\"/content/drive/MyDrive/VR_proj2/abo-images-small\", row['path'])\n",
        "    if not os.path.exists(image_path):\n",
        "        results.append(\"image_not_found\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Load image and question\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        question = row[\"question\"]\n",
        "\n",
        "        # Prepare inputs\n",
        "        inputs = processor(images=image, text=question, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Forward pass to get logits\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Get the logits and predicted token IDs\n",
        "        logits = outputs.logits\n",
        "        idx = logits.argmax(dim=-1).item()\n",
        "\n",
        "        # Use id2label mapping to get the answer\n",
        "        answer = model.config.id2label[idx]\n",
        "\n",
        "        # Handle cases where the answer might be empty or invalid\n",
        "        if not answer:\n",
        "            answer = \"no_answer\"\n",
        "        answer = re.sub(r\"[^\\w]\", \"\", answer)  # Remove punctuation\n",
        "\n",
        "    except Exception as e:\n",
        "        answer = f\"error: {str(e)}\"\n",
        "\n",
        "    results.append(answer)\n",
        "\n",
        "# Save results to a new CSV\n",
        "subset_df['vilt_answer'] = results\n",
        "subset_df.to_csv(f\"/content/drive/MyDrive/VR_proj2/vilt_vqa_results_{start_idx}_{end_idx}.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "9YMMDO4okcTM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}